{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":129596,"databundleVersionId":15545167,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":14753239,"sourceType":"datasetVersion","datasetId":9429347}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:23:47.335779Z","iopub.execute_input":"2026-02-06T13:23:47.336145Z","iopub.status.idle":"2026-02-06T13:23:47.343464Z","shell.execute_reply.started":"2026-02-06T13:23:47.336114Z","shell.execute_reply":"2026-02-06T13:23:47.342281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_profiles_path = '/kaggle/input/enigma26hack/train.csv'\n\ntest_profiles_path = '/kaggle/input/enigma26hack/test.csv'   \n\ntarget_path = '/kaggle/input/enigma26hack/target.csv'       \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:23:49.840745Z","iopub.execute_input":"2026-02-06T13:23:49.841064Z","iopub.status.idle":"2026-02-06T13:23:49.845775Z","shell.execute_reply.started":"2026-02-06T13:23:49.841037Z","shell.execute_reply":"2026-02-06T13:23:49.844716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_users = pd.read_csv(train_profiles_path)\ntest_users = pd.read_csv(test_profiles_path)\ntrain_pairs = pd.read_csv(target_path)\n\n\ndef clean_cols(df):\n    df.columns = df.columns.str.strip().str.replace(' ', '_')\n    return df\n\ntrain_users = clean_cols(train_users)\ntest_users = clean_cols(test_users)\ntrain_pairs = clean_cols(train_pairs)\n\n\ntext_cols = ['Business_Interests', 'Business_Objectives', 'Constraints', 'Role', 'Industry', 'Location_City']\nfor col in text_cols:\n    if col in train_users.columns:\n        train_users[col] = train_users[col].fillna('').astype(str).str.lower()\n        test_users[col] = test_users[col].fillna('').astype(str).str.lower()\n\n\nall_users = pd.concat([train_users, test_users], ignore_index=True)\nall_users = all_users.drop_duplicates(subset=['Profile_ID'])\n\nprint(f\"Total Unique Users: {len(all_users)}\")\nprint(f\"Training Pairs: {len(train_pairs)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:23:54.128675Z","iopub.execute_input":"2026-02-06T13:23:54.128989Z","iopub.status.idle":"2026-02-06T13:23:54.262289Z","shell.execute_reply.started":"2026-02-06T13:23:54.128964Z","shell.execute_reply":"2026-02-06T13:23:54.261246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nall_text_data = pd.concat([all_users['Business_Interests'], all_users['Business_Objectives']], axis=0)\n\ntfidf = TfidfVectorizer(max_features=500, stop_words='english')\ntfidf.fit(all_text_data)  \n\n\ninterest_matrix = tfidf.transform(all_users['Business_Interests'])\nobjective_matrix = tfidf.transform(all_users['Business_Objectives'])\n\n\nuser_id_to_idx = {uid: idx for idx, uid in enumerate(all_users['Profile_ID'])}\n\ndef get_features(pairs_df, users_df):\n \n\n    user_info = users_df.set_index('Profile_ID').to_dict('index')\n    \n    features = []\n    \n    print(f\"Generating features for {len(pairs_df)} pairs...\")\n    \n    for _, row in pairs_df.iterrows():\n        u1, u2 = row['src_user_id'], row['dst_user_id']\n        \n        if u1 not in user_id_to_idx or u2 not in user_id_to_idx:\n            features.append([0]*8) \n            continue\n            \n        idx1 = user_id_to_idx[u1]\n        idx2 = user_id_to_idx[u2]\n\n        info1 = user_info[u1]\n        info2 = user_info[u2]\n        \n        sim_interest = (interest_matrix[idx1] @ interest_matrix[idx2].T).toarray()[0][0]\n\n        sim_objective = (objective_matrix[idx1] @ objective_matrix[idx2].T).toarray()[0][0]\n        \n        cross_match_1 = (objective_matrix[idx1] @ interest_matrix[idx2].T).toarray()[0][0]\n        \n        cross_match_2 = (objective_matrix[idx2] @ interest_matrix[idx1].T).toarray()[0][0]\n        \n        b_profile_text = f\"{info2['Role']} {info2['Industry']} {info2['Location_City']} {info2['Company_Size_Employees']}\"\n\n        cons1_words = set(str(info1['Constraints']).split())\n        b_words = set(str(b_profile_text).split())\n        constraint_clash_score = len(cons1_words.intersection(b_words))\n        \n        same_location = 1 if info1['Location_City'] == info2['Location_City'] else 0\n        same_industry = 1 if info1['Industry'] == info2['Industry'] else 0\n        \n        features.append([\n            sim_interest, \n            sim_objective, \n            cross_match_1, \n            cross_match_2,\n            constraint_clash_score,\n            same_location,\n            same_industry,\n            abs(info1['Age'] - info2['Age'])\n        ])\n        \n    return np.array(features)\n\nX = get_features(train_pairs, all_users)\ny = train_pairs['compatibility_score'].values\n\nprint(\"Feature generation complete. No Dimension Mismatch!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:40:47.322053Z","iopub.execute_input":"2026-02-06T13:40:47.323836Z","iopub.status.idle":"2026-02-06T13:47:27.647491Z","shell.execute_reply.started":"2026-02-06T13:40:47.323794Z","shell.execute_reply":"2026-02-06T13:47:27.646330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = lgb.LGBMRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=8,\n    num_leaves=31,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    n_jobs=-1\n)\n\nprint(\"Training Model...\")\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    eval_metric='mse',\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50),\n        lgb.log_evaluation(period=100)\n    ]\n)\n\nprint(\"Training Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:47:59.086852Z","iopub.execute_input":"2026-02-06T13:47:59.087285Z","iopub.status.idle":"2026-02-06T13:48:08.760392Z","shell.execute_reply.started":"2026-02-06T13:47:59.087251Z","shell.execute_reply":"2026-02-06T13:48:08.759346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntest_user_ids = test_users['Profile_ID'].unique()\ntest_pairs_list = []\n\nfor u1 in test_user_ids:\n    for u2 in test_user_ids:\n        test_pairs_list.append([u1, u2])\n\ntest_pairs_df = pd.DataFrame(test_pairs_list, columns=['src_user_id', 'dst_user_id'])\nprint(f\"Generated {len(test_pairs_df)} test pairs.\")\n\nX_test = get_features(test_pairs_df, all_users)\n\ntest_preds = model.predict(X_test)\n\ntest_preds = np.clip(test_preds, 0, 1)\n\nsubmission = pd.DataFrame()\n\nsubmission['ID'] = test_pairs_df['src_user_id'].astype(str) + '_' + test_pairs_df['dst_user_id'].astype(str)\nsubmission['compatibility_score'] = test_preds\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"SUCCESS: 'submission.csv' saved!\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:48:12.513713Z","iopub.execute_input":"2026-02-06T13:48:12.514029Z","iopub.status.idle":"2026-02-06T13:51:13.422849Z","shell.execute_reply.started":"2026-02-06T13:48:12.514005Z","shell.execute_reply":"2026-02-06T13:51:13.421737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\nval_preds = model.predict(X_val)\n\nmse_score = mean_squared_error(y_val, val_preds)\nrmse_score = np.sqrt(mse_score)\n\nprint(\"=\"*30)\nprint(f\" FINAL VALIDATION MSE: {mse_score:.6f}\")\nprint(f\"   (Lower is better. Target is < 0.05 approx)\")\nprint(f\"   Root MSE (RMSE):      {rmse_score:.6f}\")\nprint(\"=\"*30)\n\nprint(\"\\n--- Feature Importance Graph ---\")\nplt.figure(figsize=(10, 5))\nlgb.plot_importance(model, max_num_features=10, height=0.5)\nplt.title(\"What drives Compatibility?\")\nplt.show()\n\nplt.figure(figsize=(8, 8))\nplt.scatter(y_val, val_preds, alpha=0.2, color='blue')\nplt.plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=2, label='Perfect Prediction')\nplt.xlabel(\"Actual Score (Truth)\")\nplt.ylabel(\"Predicted Score (Model)\")\nplt.title(\"Prediction Accuracy Check\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:55:00.666145Z","iopub.execute_input":"2026-02-06T13:55:00.666525Z","iopub.status.idle":"2026-02-06T13:55:03.745226Z","shell.execute_reply.started":"2026-02-06T13:55:00.666494Z","shell.execute_reply":"2026-02-06T13:55:03.743811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\n\nprint(\"Initializing XGBoost...\")\n\nxgb_model = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=8,          \n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective='reg:squarederror',\n    n_jobs=-1,\n    random_state=42,\n    early_stopping_rounds=50\n)\n\nxgb_model.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    verbose=100\n)\n\nxgb_test_preds = xgb_model.predict(X_test)\nxgb_test_preds = np.clip(xgb_test_preds, 0, 1)\n\nsub_xgb = submission.copy()\nsub_xgb['compatibility_score'] = xgb_test_preds\nsub_xgb.to_csv('submission_xgboost.csv', index=False)\n\nprint(\"XGBoost Model Trained & Saved as 'submission_xgboost.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:55:15.004815Z","iopub.execute_input":"2026-02-06T13:55:15.005280Z","iopub.status.idle":"2026-02-06T13:55:34.086524Z","shell.execute_reply.started":"2026-02-06T13:55:15.005237Z","shell.execute_reply":"2026-02-06T13:55:34.085567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nensemble_preds = (test_preds + xgb_test_preds) / 2\n\n\nensemble_snapped = [snap_to_nearest(p, sorted_fractions) for p in ensemble_preds]\nn\nsub_ensemble = submission.copy()\nsub_ensemble['compatibility_score'] = ensemble_snapped\nsub_ensemble.to_csv('submission_ensemble.csv', index=False)\n\nprint(\"Created 'submission_ensemble.csv' (Averaged Model)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:56:23.352547Z","iopub.execute_input":"2026-02-06T13:56:23.353024Z","iopub.status.idle":"2026-02-06T13:56:24.189317Z","shell.execute_reply.started":"2026-02-06T13:56:23.352971Z","shell.execute_reply":"2026-02-06T13:56:24.188309Z"}},"outputs":[],"execution_count":null}]}